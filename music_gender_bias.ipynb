{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044edefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import scipy.special as sps\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "035bcddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2154</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2241</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3270</td>\n",
       "      <td>6</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4003</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5080</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268362</th>\n",
       "      <td>120320</td>\n",
       "      <td>1480735</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268363</th>\n",
       "      <td>120320</td>\n",
       "      <td>2626622</td>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268364</th>\n",
       "      <td>120320</td>\n",
       "      <td>2465242</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268365</th>\n",
       "      <td>120320</td>\n",
       "      <td>14175074</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268366</th>\n",
       "      <td>120320</td>\n",
       "      <td>4304966</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268367 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  track_id  play_count gender\n",
       "0             1      2154           4      m\n",
       "1             1      2241           4      m\n",
       "2             1      3270           6      m\n",
       "3             1      4003           2      m\n",
       "4             1      5080           2      m\n",
       "...         ...       ...         ...    ...\n",
       "268362   120320   1480735           2      m\n",
       "268363   120320   2626622           3      m\n",
       "268364   120320   2465242           4      m\n",
       "268365   120320  14175074           2      m\n",
       "268366   120320   4304966           2      m\n",
       "\n",
       "[268367 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('sampled_interactions.tsv', sep='\\t', names=['user_id', 'track_id', 'play_count', 'gender'])\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31999e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "men: 17977\n",
      "women: 4939\n",
      "total listening events: 1967620\n",
      "unique tracks: 7140\n",
      "average sum of track playcounts: 275.57703081232495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>12009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>8427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>17837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>10192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          play_count\n",
       "track_id            \n",
       "482            12009\n",
       "521             8427\n",
       "724            17837\n",
       "1041             501\n",
       "1112           10192"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = sample[['user_id', 'track_id', 'play_count']]\n",
    "users = sample[['user_id', 'gender']].drop_duplicates()\n",
    "\n",
    "men = set(users[users['gender'] == 'm']['user_id'].values)\n",
    "women = set(users[users['gender'] == 'f']['user_id'].values)\n",
    "print(f'men: {len(men)}')\n",
    "print(f'women: {len(women)}')\n",
    "print(f'total listening events: {interactions[\"play_count\"].sum()}')\n",
    "\n",
    "track_ids = np.sort(np.array(interactions['track_id'].unique(), dtype = np.int32))\n",
    "print(f'unique tracks: {len(track_ids)}')\n",
    "\n",
    "popularities_df = interactions[['track_id', 'play_count']].groupby('track_id').sum()\n",
    "popularities = np.array(popularities_df['play_count'].values)\n",
    "\n",
    "print(f'average sum of track playcounts: {popularities.mean()}')\n",
    "popularities_df.head(5) # P(t)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e12e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example listening history: [2154 2241 3270 4003 5080 6353 7724 8543]\n",
      "average length of user history: 11.65900599530802\n"
     ]
    }
   ],
   "source": [
    "grouped_by_users = interactions[['user_id', 'track_id']].groupby('user_id')\n",
    "user_histories = {user_id: group['track_id'].values for user_id, group in grouped_by_users}\n",
    "\n",
    "print(f'example listening history: {user_histories[1]}')\n",
    "print(f'average length of user history: {np.mean([len(value) for key, value in user_histories.items()])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c982cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decile-binning so that the cumulative popularity of all tracks in one bin is approximately 10% of the total popularity\n",
    "sorted_pops_df = popularities_df.sort_values('play_count', ascending = False)\n",
    "sorted_tracks = np.array(sorted_pops_df.index.values)\n",
    "sorted_pops = np.array(sorted_pops_df['play_count'].values)\n",
    "\n",
    "total_popularity = popularities.sum()\n",
    "bin_limit = total_popularity / 10\n",
    "\n",
    "bins = [list() for i in range(0,10)]\n",
    "\n",
    "current_pop_sum = 0\n",
    "current_bin = 0\n",
    "for i, track in np.ndenumerate(sorted_tracks):\n",
    "    current_pop_sum = current_pop_sum + sorted_pops[i]\n",
    "    \n",
    "    bins[current_bin].append(track) \n",
    "    \n",
    "    if current_pop_sum >= bin_limit:\n",
    "        current_pop_sum = 0\n",
    "        current_bin = current_bin + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c46490f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268366     1.000000\n",
       "171755     1.000000\n",
       "171756     1.000000\n",
       "171758     1.000000\n",
       "70998      1.000000\n",
       "            ...    \n",
       "16803     14.049217\n",
       "209478    15.721104\n",
       "198703    15.905295\n",
       "261966    16.585384\n",
       "198710    20.000000\n",
       "Name: play_count, Length: 268367, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 20))\n",
    "\n",
    "interactions['scaled_counts'] = scaler.fit_transform(interactions[['play_count']])\n",
    "interactions = interactions.drop(columns = 'play_count')\n",
    "interactions = interactions.rename(columns = {'scaled_counts': 'play_count'})\n",
    "interactions['play_count'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7c0f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "REC_LIST_SIZE = 10\n",
    "zeros = np.zeros(len(track_ids), dtype = np.int32)\n",
    "ones = np.ones(len(track_ids), dtype = np.int32)\n",
    "\n",
    "def non_zero_median(a): #  the median in these distributions is typically 0, so np.median gets div-by-zero\n",
    "    return np.median(a[a.nonzero()])\n",
    "\n",
    "\n",
    "class AlgoResult:\n",
    "    def __init__(self, name, recs, score):\n",
    "        self.name = name\n",
    "        self.recs = recs\n",
    "        self.score = score\n",
    "\n",
    "class Evaluation:        \n",
    "    def __init__(self, testset, algos_list):\n",
    "        self.users = set([uid for (uid, _, _) in testset])\n",
    "        self.women = set([uid for uid in self.users if uid in women])\n",
    "        self.men = set([uid for uid in self.users if uid in men])\n",
    "\n",
    "        self.algos_list = algos_list # list of AlgoResults\n",
    "        \n",
    "        self.metrics = [np.mean, non_zero_median, np.var, sp.skew, sp.kurtosis]        \n",
    "                \n",
    "    def calc_metrics(self, uid, rec_list):\n",
    "        h = np.where(np.isin(track_ids, user_histories[uid]), ones, zeros) * popularities\n",
    "        r = np.where(np.isin(track_ids, rec_list[:len(user_histories[uid])]), ones, zeros) * popularities\n",
    "        \n",
    "        calc = []\n",
    "        for metric in self.metrics:\n",
    "            mh = metric(h)\n",
    "            mr = metric(r)\n",
    "            calc.append(100 * (mr - mh) / mh)\n",
    "            \n",
    "            \n",
    "        kt, _ = sp.kendalltau(h,r)    \n",
    "        calc.append(kt)\n",
    "        return calc\n",
    "\n",
    "    def aggregate_metrics(self, recs, name, score, gender = None):\n",
    "        if gender == \"women\":\n",
    "            metrics = np.array([self.calc_metrics(uid, rec_list) for (uid, rec_list) in recs if uid in women])\n",
    "        elif gender == \"men\":\n",
    "            metrics = np.array([self.calc_metrics(uid, rec_list) for (uid, rec_list) in recs if uid in men])\n",
    "        else:\n",
    "            gender = \"all\"\n",
    "            metrics = np.array([self.calc_metrics(uid, rec_list) for (uid, rec_list) in recs])   \n",
    "            \n",
    "        metrics = np.median(metrics, axis = 0)\n",
    "        return pd.Series({'algorithm': name, 'gender': gender, 'mean': metrics[0], 'median': metrics[1],\n",
    "                          'variance': metrics[2], 'skew': metrics[3], 'kurtosis': metrics[4],\n",
    "                          'kendall-tau': metrics[5], 'rmse': score})\n",
    "            \n",
    "    def eval_algo(self, algo):\n",
    "        print(f'processing {algo.name}')\n",
    "        \n",
    "        a = self.aggregate_metrics(algo.recs, algo.name, algo.score)\n",
    "        b = self.aggregate_metrics(algo.recs, algo.name, algo.score, \"women\")\n",
    "        c = self.aggregate_metrics(algo.recs, algo.name, algo.score, \"men\")\n",
    "        \n",
    "        return pd.DataFrame(data = [a, b, c])\n",
    " \n",
    "    def process(self):\n",
    "        return pd.concat([self.eval_algo(algo) for algo in self.algos_list], ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "    def calc_kl(self, uid, rec_list):\n",
    "        print(uid, end = '\\r')\n",
    "        #sum_kl = 0\n",
    "        \n",
    "        #for b in bins:\n",
    "            #zeros_b = np.zeros(len(b), dtype = np.int32)\n",
    "            #ones_b = np.ones(len(b), dtype = np.int32)\n",
    "            #h = np.where(np.isin(b, user_histories[uid]), ones_b, zeros_b) * popularities\n",
    "            #r = np.where(np.isin(b, rec_list[:len(user_histories[uid])]), ones_b, zeros_b) * popularities\n",
    "            #h = [popularities_df.loc[track]['play_count'] if track in user_histories[uid] else 0 for track in b]\n",
    "            #r = [popularities_df.loc[track]['play_count'] if track in rec_list[:len(user_histories[uid])] else 0 for track in b]\n",
    "            #h = np.array(h)\n",
    "            #r = np.array(r)\n",
    "            \n",
    "            #sum_kl = sum_kl + np.sum(np.where(h != 0, h * np.log(h / r), 0))\n",
    "            #sum_kl = sum_kl + sum(sps.kl_div(h,r))\n",
    "                        \n",
    "        #return sum_kl\n",
    "        \n",
    "        \n",
    "        h = np.where(np.isin(track_ids, user_histories[uid]), ones, zeros) * popularities\n",
    "        r = np.where(np.isin(track_ids, rec_list[:len(user_histories[uid])]), ones, zeros) * popularities\n",
    "\n",
    "        #return sps.kl_div(h,r)\n",
    "        return sp.kendalltau(h,r)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08374da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import NormalPredictor, BaselineOnly, KNNWithMeans, KNNBaseline, SVD, NMF, SlopeOne, CoClustering\n",
    "from surprise.accuracy import rmse\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "dataset = Dataset.load_from_df(interactions, Reader(rating_scale=(1, interactions['play_count'].max())))\n",
    "\n",
    "# param_grid = \n",
    "# SVD - {'n_factors': [20, 50, 100, 150], 'n_epochs': [5, 10, 20, 25, 30], 'lr_all': [0.002, 0.005, 0.01],\n",
    "#        'reg_all': [0.02, 0.1, 0.4, 0.6], 'verbose': [True]}\n",
    "# NMF - {'n_factors': [5, 15, 30], 'n_epochs': [5, 15, 50, 75], 'biased': [True, False] , 'verbose': [True]}\n",
    "# Co-clustering - {'n_cltr_u ': [3,5,10], 'n_cltr_i ': [3,5,10], 'n_epochs': [10, 20, 35, 50], 'verbose': [True]}\n",
    "# KNNWithMeans & KNNBaseline - {'k': [10, 20, 40, 75, 100], 'verbose': [True],\n",
    "#                               'sim_options': {'name': ['msd', 'cosine'], 'user_based': [False]}}\n",
    "\n",
    "#gs = GridSearchCV(KNNBaseline, param_grid, measures = ['rmse', 'mae'], cv = 5, joblib_verbose = True, n_jobs = -1)\n",
    "#gs.fit(dataset)\n",
    "\n",
    "#print(gs.best_score['rmse'])\n",
    "#print(gs.best_params['rmse'])\n",
    "#algo = gs.best_estimator['rmse']\n",
    "# SVD - {'n_factors': 20, 'n_epochs': 25, 'lr_all': 0.005, 'reg_all': 0.6, 'verbose': True}\n",
    "# NMF - {'n_factors': 5, 'n_epochs': 75, 'biased': True, 'verbose': True}\n",
    "# Co-clustering - {'n_cltr_u': 3, 'n_cltr_i': 3, 'n_epochs': 10, 'verbose': True}\n",
    "# KNNWithMeans & KNNBaseline - {'k': 100, 'verbose': True, 'sim_options': {'name': 'cosine', 'user_based': False}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dec70117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "def get_top_n(predictions, n = REC_LIST_SIZE):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def train_and_rec(trainset, testset, algorithm):\n",
    "    algorithm.fit(trainset)\n",
    "    predictions = algorithm.test(testset)  \n",
    "    top_n = get_top_n(predictions)\n",
    " \n",
    "    score = rmse(predictions, verbose=False)\n",
    "    \n",
    "    return score, [(uid, [iid for (iid, _) in user_ratings]) for uid, user_ratings in top_n.items()]\n",
    "\n",
    "def get_algo_results(trainset, testset):\n",
    "    algorithms = [NormalPredictor(),\n",
    "                  BaselineOnly(verbose = True),\n",
    "                  SlopeOne(),\n",
    "                  KNNWithMeans(verbose = True, k = 100, sim_options = {'name': 'cosine', 'user_based': False}),\n",
    "                  KNNBaseline(verbose = True, k = 100, sim_options = {'name': 'cosine', 'user_based': False}),\n",
    "                  SVD(verbose = True, random_state = 42, n_epochs = 25, n_factors = 20, lr_all = 0.005, reg_all = 0.6),\n",
    "                  NMF(verbose = True, random_state = 42, n_epochs = 75, n_factors = 5, biased = True),\n",
    "                  CoClustering(verbose = True, random_state = 42, n_cltr_u = 3, n_cltr_i = 3, n_epochs = 10)]       \n",
    "        \n",
    "    res = []\n",
    "    for algorithm in algorithms:\n",
    "        score, recs = train_and_rec(trainset, testset, algorithm)\n",
    "        res.append(AlgoResult(type(algorithm).__name__, recs, score))\n",
    "           \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "df2ee16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tervel\\AppData\\Local\\Temp\\ipykernel_14100\\1858230678.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  algorithm.fit(trainset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 50\n",
      "Processing epoch 51\n",
      "Processing epoch 52\n",
      "Processing epoch 53\n",
      "Processing epoch 54\n",
      "Processing epoch 55\n",
      "Processing epoch 56\n",
      "Processing epoch 57\n",
      "Processing epoch 58\n",
      "Processing epoch 59\n",
      "Processing epoch 60\n",
      "Processing epoch 61\n",
      "Processing epoch 62\n",
      "Processing epoch 63\n",
      "Processing epoch 64\n",
      "Processing epoch 65\n",
      "Processing epoch 66\n",
      "Processing epoch 67\n",
      "Processing epoch 68\n",
      "Processing epoch 69\n",
      "Processing epoch 70\n",
      "Processing epoch 71\n",
      "Processing epoch 72\n",
      "Processing epoch 73\n",
      "Processing epoch 74\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "processing NormalPredictor\n",
      "processing BaselineOnly\n",
      "processing SlopeOne\n",
      "processing KNNWithMeans\n",
      "processing KNNBaseline\n",
      "processing SVD\n",
      "processing NMF\n",
      "processing CoClustering\n",
      "680.9743235111237\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = train_test_split(dataset, test_size=.2, random_state = 42)\n",
    "res = get_algo_results(trainset, testset)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "evals = Evaluation(testset, res)\n",
    "scores = evals.process()\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "scores.to_csv('output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a97933f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>gender</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>variance</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>kendall-tau</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NormalPredictor</td>\n",
       "      <td>all</td>\n",
       "      <td>-83.235975</td>\n",
       "      <td>2.840673</td>\n",
       "      <td>-91.979982</td>\n",
       "      <td>37.721537</td>\n",
       "      <td>77.794421</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.247181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NormalPredictor</td>\n",
       "      <td>women</td>\n",
       "      <td>-82.924570</td>\n",
       "      <td>1.839306</td>\n",
       "      <td>-92.172687</td>\n",
       "      <td>35.695129</td>\n",
       "      <td>73.986031</td>\n",
       "      <td>0.447276</td>\n",
       "      <td>0.247181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NormalPredictor</td>\n",
       "      <td>men</td>\n",
       "      <td>-83.302088</td>\n",
       "      <td>3.130148</td>\n",
       "      <td>-91.918975</td>\n",
       "      <td>38.293489</td>\n",
       "      <td>78.973906</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.247181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BaselineOnly</td>\n",
       "      <td>all</td>\n",
       "      <td>-83.108081</td>\n",
       "      <td>3.562000</td>\n",
       "      <td>-91.914156</td>\n",
       "      <td>37.634934</td>\n",
       "      <td>77.670031</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.183616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BaselineOnly</td>\n",
       "      <td>women</td>\n",
       "      <td>-82.870861</td>\n",
       "      <td>2.028526</td>\n",
       "      <td>-92.148991</td>\n",
       "      <td>35.723443</td>\n",
       "      <td>74.114849</td>\n",
       "      <td>0.447276</td>\n",
       "      <td>0.183616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>BaselineOnly</td>\n",
       "      <td>men</td>\n",
       "      <td>-83.171336</td>\n",
       "      <td>3.974895</td>\n",
       "      <td>-91.823457</td>\n",
       "      <td>38.214521</td>\n",
       "      <td>78.721728</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.183616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>SlopeOne</td>\n",
       "      <td>all</td>\n",
       "      <td>-83.211873</td>\n",
       "      <td>2.770307</td>\n",
       "      <td>-91.974407</td>\n",
       "      <td>37.726948</td>\n",
       "      <td>77.813245</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.195959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>SlopeOne</td>\n",
       "      <td>women</td>\n",
       "      <td>-82.924570</td>\n",
       "      <td>1.772855</td>\n",
       "      <td>-92.172687</td>\n",
       "      <td>35.695129</td>\n",
       "      <td>73.986031</td>\n",
       "      <td>0.447276</td>\n",
       "      <td>0.195959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>SlopeOne</td>\n",
       "      <td>men</td>\n",
       "      <td>-83.276109</td>\n",
       "      <td>3.061224</td>\n",
       "      <td>-91.905325</td>\n",
       "      <td>38.317732</td>\n",
       "      <td>79.004219</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.195959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>all</td>\n",
       "      <td>-83.125680</td>\n",
       "      <td>3.581702</td>\n",
       "      <td>-91.915320</td>\n",
       "      <td>37.634483</td>\n",
       "      <td>77.660493</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.200465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>women</td>\n",
       "      <td>-82.870861</td>\n",
       "      <td>2.028526</td>\n",
       "      <td>-92.147446</td>\n",
       "      <td>35.723443</td>\n",
       "      <td>74.114849</td>\n",
       "      <td>0.447276</td>\n",
       "      <td>0.200465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>men</td>\n",
       "      <td>-83.190865</td>\n",
       "      <td>4.026975</td>\n",
       "      <td>-91.823811</td>\n",
       "      <td>38.214125</td>\n",
       "      <td>78.720267</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.200465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>KNNBaseline</td>\n",
       "      <td>all</td>\n",
       "      <td>-83.140414</td>\n",
       "      <td>3.510851</td>\n",
       "      <td>-91.919316</td>\n",
       "      <td>37.671949</td>\n",
       "      <td>77.721149</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.199292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>KNNBaseline</td>\n",
       "      <td>women</td>\n",
       "      <td>-82.870861</td>\n",
       "      <td>2.028526</td>\n",
       "      <td>-92.148346</td>\n",
       "      <td>35.723443</td>\n",
       "      <td>74.114849</td>\n",
       "      <td>0.447276</td>\n",
       "      <td>0.199292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>KNNBaseline</td>\n",
       "      <td>men</td>\n",
       "      <td>-83.195734</td>\n",
       "      <td>3.926234</td>\n",
       "      <td>-91.838434</td>\n",
       "      <td>38.232832</td>\n",
       "      <td>78.826723</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.199292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>SVD</td>\n",
       "      <td>all</td>\n",
       "      <td>-83.108081</td>\n",
       "      <td>3.710555</td>\n",
       "      <td>-91.914156</td>\n",
       "      <td>37.632695</td>\n",
       "      <td>77.609654</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.183367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>SVD</td>\n",
       "      <td>women</td>\n",
       "      <td>-82.870861</td>\n",
       "      <td>2.194907</td>\n",
       "      <td>-92.148260</td>\n",
       "      <td>35.695129</td>\n",
       "      <td>73.986031</td>\n",
       "      <td>0.447276</td>\n",
       "      <td>0.183367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>SVD</td>\n",
       "      <td>men</td>\n",
       "      <td>-83.171336</td>\n",
       "      <td>4.207851</td>\n",
       "      <td>-91.823457</td>\n",
       "      <td>38.206575</td>\n",
       "      <td>78.686185</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.183367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>NMF</td>\n",
       "      <td>all</td>\n",
       "      <td>-83.103008</td>\n",
       "      <td>3.744099</td>\n",
       "      <td>-91.914156</td>\n",
       "      <td>37.627019</td>\n",
       "      <td>77.570862</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.187481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>NMF</td>\n",
       "      <td>women</td>\n",
       "      <td>-82.870861</td>\n",
       "      <td>2.194907</td>\n",
       "      <td>-92.147468</td>\n",
       "      <td>35.695129</td>\n",
       "      <td>73.986031</td>\n",
       "      <td>0.447276</td>\n",
       "      <td>0.187481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>NMF</td>\n",
       "      <td>men</td>\n",
       "      <td>-83.163515</td>\n",
       "      <td>4.220399</td>\n",
       "      <td>-91.823457</td>\n",
       "      <td>38.178037</td>\n",
       "      <td>78.538756</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.187481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>all</td>\n",
       "      <td>-83.177140</td>\n",
       "      <td>3.180620</td>\n",
       "      <td>-91.951989</td>\n",
       "      <td>37.678013</td>\n",
       "      <td>77.721149</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.212715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>women</td>\n",
       "      <td>-82.892806</td>\n",
       "      <td>1.839306</td>\n",
       "      <td>-92.163645</td>\n",
       "      <td>35.723443</td>\n",
       "      <td>74.114849</td>\n",
       "      <td>0.447276</td>\n",
       "      <td>0.212715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>men</td>\n",
       "      <td>-83.242632</td>\n",
       "      <td>3.596404</td>\n",
       "      <td>-91.871782</td>\n",
       "      <td>38.239698</td>\n",
       "      <td>78.826723</td>\n",
       "      <td>0.447151</td>\n",
       "      <td>0.212715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        algorithm gender       mean    median   variance  \\\n",
       "0            0  NormalPredictor    all -83.235975  2.840673 -91.979982   \n",
       "1            1  NormalPredictor  women -82.924570  1.839306 -92.172687   \n",
       "2            2  NormalPredictor    men -83.302088  3.130148 -91.918975   \n",
       "3            3     BaselineOnly    all -83.108081  3.562000 -91.914156   \n",
       "4            4     BaselineOnly  women -82.870861  2.028526 -92.148991   \n",
       "5            5     BaselineOnly    men -83.171336  3.974895 -91.823457   \n",
       "6            6         SlopeOne    all -83.211873  2.770307 -91.974407   \n",
       "7            7         SlopeOne  women -82.924570  1.772855 -92.172687   \n",
       "8            8         SlopeOne    men -83.276109  3.061224 -91.905325   \n",
       "9            9     KNNWithMeans    all -83.125680  3.581702 -91.915320   \n",
       "10          10     KNNWithMeans  women -82.870861  2.028526 -92.147446   \n",
       "11          11     KNNWithMeans    men -83.190865  4.026975 -91.823811   \n",
       "12          12      KNNBaseline    all -83.140414  3.510851 -91.919316   \n",
       "13          13      KNNBaseline  women -82.870861  2.028526 -92.148346   \n",
       "14          14      KNNBaseline    men -83.195734  3.926234 -91.838434   \n",
       "15          15              SVD    all -83.108081  3.710555 -91.914156   \n",
       "16          16              SVD  women -82.870861  2.194907 -92.148260   \n",
       "17          17              SVD    men -83.171336  4.207851 -91.823457   \n",
       "18          18              NMF    all -83.103008  3.744099 -91.914156   \n",
       "19          19              NMF  women -82.870861  2.194907 -92.147468   \n",
       "20          20              NMF    men -83.163515  4.220399 -91.823457   \n",
       "21          21     CoClustering    all -83.177140  3.180620 -91.951989   \n",
       "22          22     CoClustering  women -82.892806  1.839306 -92.163645   \n",
       "23          23     CoClustering    men -83.242632  3.596404 -91.871782   \n",
       "\n",
       "         skew   kurtosis  kendall-tau      rmse  \n",
       "0   37.721537  77.794421     0.447151  0.247181  \n",
       "1   35.695129  73.986031     0.447276  0.247181  \n",
       "2   38.293489  78.973906     0.447151  0.247181  \n",
       "3   37.634934  77.670031     0.447151  0.183616  \n",
       "4   35.723443  74.114849     0.447276  0.183616  \n",
       "5   38.214521  78.721728     0.447151  0.183616  \n",
       "6   37.726948  77.813245     0.447151  0.195959  \n",
       "7   35.695129  73.986031     0.447276  0.195959  \n",
       "8   38.317732  79.004219     0.447151  0.195959  \n",
       "9   37.634483  77.660493     0.447151  0.200465  \n",
       "10  35.723443  74.114849     0.447276  0.200465  \n",
       "11  38.214125  78.720267     0.447151  0.200465  \n",
       "12  37.671949  77.721149     0.447151  0.199292  \n",
       "13  35.723443  74.114849     0.447276  0.199292  \n",
       "14  38.232832  78.826723     0.447151  0.199292  \n",
       "15  37.632695  77.609654     0.447151  0.183367  \n",
       "16  35.695129  73.986031     0.447276  0.183367  \n",
       "17  38.206575  78.686185     0.447151  0.183367  \n",
       "18  37.627019  77.570862     0.447151  0.187481  \n",
       "19  35.695129  73.986031     0.447276  0.187481  \n",
       "20  38.178037  78.538756     0.447151  0.187481  \n",
       "21  37.678013  77.721149     0.447151  0.212715  \n",
       "22  35.723443  74.114849     0.447276  0.212715  \n",
       "23  38.239698  78.826723     0.447151  0.212715  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35f922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8c7478fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a84210d090402dacbe0b09018cc97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "user_item = csr_matrix((interactions['play_count'], (interactions['user_id'], interactions['track_id'])),\n",
    "                          shape=(interactions['user_id'].max() + 1, interactions['track_id'].max() + 1))\n",
    "item_user = user_item.T.tocsr()\n",
    "\n",
    "\n",
    "als = AlternatingLeastSquares(factors = 10)\n",
    "als.fit(item_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fca97f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = als.recommend(7, user_item[7], 10)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "02d319df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#train_val, test = train_test_split(interactions, test_size = 0.2)\n",
    "#train, validation = train_test_split(train_val, test_size = 0.25) # 0.25*0.8 = 0.2\n",
    "#print(len(train))\n",
    "#print(len(validation))\n",
    "#print(len(test))\n",
    "\n",
    "#len(test[test['user_id'].isin(users[users['gender'] == 'f']['user_id'].values)]['user_id'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
